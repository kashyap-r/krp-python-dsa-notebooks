{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c43a3361",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c335f6f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d1a7b2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7ed8bff",
   "metadata": {},
   "source": [
    "25 additional ML-flavoured coding challenges (Python)\n",
    "\n",
    "Designed to be solvable in ~10–20 minutes each; most require only core libs (math, collections, heapq, etc.).\n",
    "\n",
    "Confusion Matrix Metrics: Given TP, FP, TN, FN, compute Precision, Recall, F1 (handle zero-div).\n",
    "\n",
    "ROC Points: Given scores+labels, produce ROC curve points (sorted by score); compute AUC via trapezoids.\n",
    "\n",
    "PR-AUC: As above but Precision–Recall AUC; careful with ties and stepwise areas.\n",
    "\n",
    "Balanced Accuracy & MCC: Compute Balanced Accuracy and Matthew’s Correlation from counts.\n",
    "\n",
    "Stratified Split: Split (X, y) into train/val with class-ratio preserved; return indices.\n",
    "\n",
    "K-Fold Indexer: Produce k folds (list of (train_ids, val_ids)) with near-equal sizes.\n",
    "\n",
    "Online Mean/Variance: Welford’s algorithm to stream-compute mean and variance.\n",
    "\n",
    "Exponential Moving Average: Implement EMA for a series (alpha given).\n",
    "\n",
    "Time-window Aggregates: Given events (ts, value), compute rolling sum over last W seconds (use deque).\n",
    "\n",
    "Cosine Similarity: Given two sparse vectors as dicts, compute cosine similarity efficiently.\n",
    "\n",
    "TF-IDF (mini): Given list of docs (token lists), compute tf-idf for each term in one target doc.\n",
    "\n",
    "K-Means (one iteration): Given points and current centroids, assign & recompute new centroids.\n",
    "\n",
    "Softmax + Cross-Entropy: Numerically stable softmax; compute average CE for logits+labels.\n",
    "\n",
    "Sigmoid + BCE: Stable sigmoid and binary cross-entropy with epsilon for extremes.\n",
    "\n",
    "Top-K by Score: Stream of (id, score) → maintain top-k using a min-heap.\n",
    "\n",
    "Deduplicate by Key: From records with id, keep the one with max timestamp; return stable order by time.\n",
    "\n",
    "Sessionize Clicks: Group user events into sessions: new session if gap > T minutes.\n",
    "\n",
    "Log Latency SLOs: From microservice logs, compute p50/p90/p99 latencies per route; output failing routes vs SLO.\n",
    "\n",
    "LRU Cache: Classic LRU with O(1) get/put (OrderedDict or custom DLL + hash).\n",
    "\n",
    "Tokenize + N-grams: Clean text (lower/strip punctuation) and output counts of n-grams (n given).\n",
    "\n",
    "Levenshtein Distance: Edit distance DP; return distance & one alignment path.\n",
    "\n",
    "Vector Search (Brute): Given query vector and corpus, return top-k by cosine; show complexity.\n",
    "\n",
    "Min Hash-like Signature (toy): Compute simple k hash functions on token set to build a signature vector.\n",
    "\n",
    "A/B Results Calc: Given conversions & trials for A and B, compute absolute & relative lift and a z-test p-value.\n",
    "\n",
    "Feature Scaling: Implement standard scaling (z-score) and min–max scaling with fit/transform API."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
